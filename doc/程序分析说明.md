程序分析说明
======
**此文档包含程序分析相关类的说明以及执行流程的简要说明**

Deca作为一个工具包括静态分析器和运行时优化器，静态分析器提取目标程序的UDF和UDT
运行时优化器在运行时拦截提交的Job，并在将Job提交给Spark前对其优化。其中主要用到了工具[Soot](https://sable.github.io/soot/)

目标：拿到job所有stage的字段类型信息，并传给具体Task的读写端。

优化流程主要分为以下四个模块：（**目前根据工程目标使用了前两个模块**)

[1.Preprocessing：迭代融合](#1)

[2.Analysis：指针分析](#2)

[3.Decomposition：UDT类型分解](#3)

[4.Linking](#4)

*****************

**流程总览：** Spark在提交Job的时候，org.apache.spark.DecaContext截获Job,重写SparkContext的提交Job的方法，调用DecaCotext的anaylze方法。

```scala
override def runJob[T, U: ClassTag](
                                       rdd: RDD[T],
                                       func: (TaskContext, Iterator[T]) => U,
                                       partitions: Seq[Int],
                                       allowLocal: Boolean,
                                       resultHandler: (Int, U) => Unit): Unit = {
    try {
      val analyzeEnable = SparkEnv.get.conf.getBoolean("spark.optimize.analyze",true)
      if(analyzeEnable) {
        val start = System.currentTimeMillis()
        //调用anaylze方法，分析优化Job代码的入口
        val decaRDD = analyze(rdd, func, partitions, resultHandler)
        val end = System.currentTimeMillis()
        logInfo("!!Deca analyze and transform the program cost:" + (end - start) / 1000)
        if (decaRDD != null) {
          super.runJob(decaRDD, func, partitions, false, resultHandler)
        }else{
          super.runJob(rdd, func, partitions, false, resultHandler)
        }
      }else{
        super.runJob(rdd, func, partitions, false, resultHandler)
      }
```
analyze方法调用org.apache.spark.scheduler.DAGAnalyzer的formPhase方法，对此Job的代码进行分析和转换。

`setStageKeyValueTypeInfos(DAGAnalyzer.formPhase(finalRDD, func, partitions, resultHandler, this))`

下面我们看一下formPhase的方法体，此方法包含了整个具体优化的流程，并返回一个记录每个stage的字段信息的map。First：利用Spark本身的stage划分机制，构建与stage一一对应的Phase。Second：对每一个Phase作处理，包括迭代融合和指针分析，调用对应的函数fuseIter和 PointerAnalyzer.transform；指针分析结束后，拿到返回的localNewSiteInfos 里面的FieldInfoMap，调用KeyValueUtil.putKeyAndValueType方法处理每个field的详细信息，并按照系统定义的Json格式返回。
```scala
 def formPhase[T, U](finalRDD: RDD[T],
                      func: (TaskContext, Iterator[T]) => U,
                      partitions: Seq[Int],
                      resultHandler: (Int, U) => Unit,
                      dc: DecaContext): mutable.Map[Int, java.util.List[(String, String)]] = {
    val properties = localProperties.get
    val jobId = nextJobId.getAndIncrement()
    ...... ......
    //利用Spark的stage划分机制构建Phase
    val finalStage = stageScheduler.newResultStage(finalRDD.asInstanceOf[RDD[_]],
      func.asInstanceOf[(TaskContext, Iterator[_]) => _],
      partitions_2, jobId, callSite)
    val finalPhase = new Phase(finalStage.id, finalStage.rdd, List[Phase]())
    allPhasesMap(finalPhase) = finalStage
    allPhases = finalPhase +: allPhases
    //构建phase之间的父子关系
    handleStage(finalPhase, finalStage, stageScheduler)
    for (phase <- allPhases.sortBy(_.id)) {
      //处理每个cacheRDD，生成cachePhasesMap，一个存在Cache的Phase划分成cacheWritePhase和cacheReadPhase的方法是以cacheRDD为界，之前的RDD链构成cacheWritePhase，之后的构成cacheReadPhase。
      handleCacheRDDFromChain(phase)
    }
   ...... ......
    for (phase <- allPhases) {
      TimeRecorder.jobID = jobId
      sootContext = new Context(preload = false, classpath = System.getProperty("java.class.path"))
      val fusionStart = System.currentTimeMillis()
      //迭代融合，返回融合后的stage-function-class
      val fusionClass = fuseIter(phase, resultFuncTuple)
      val fusionEnd = System.currentTimeMillis()
      TimeRecorder.fusionTime = fusionEnd - fusionStart
      TimeRecorder.stageID = fusionClass.getName
      sootContext.writeOutput(fusionClass)
      //指针分析，返回local的相关信息
      val localNewSiteInfos = PointerAnalyzer.transform(sootContext, fusionClass, phase)
      if (localNewSiteInfos.size() != 0 || phase.kind == "Result") {
        var shufflefieldInfoMap: mutable.Map[SootField, FieldInfo] = new mutable.HashMap[SootField, FieldInfo].empty
        var cacheFieldInfoMap: mutable.Map[SootField, FieldInfo] = new mutable.HashMap[SootField, FieldInfo].empty
        if (localNewSiteInfos.size() != 0) {
          val shuffleLocalNewSiteInfos = localNewSiteInfos.filter(_.genericType == "shuffle")
          val cacheLocalNewSiteInfos = localNewSiteInfos.filter(_.genericType == "cache")
          if (shuffleLocalNewSiteInfos.nonEmpty) {
            shufflefieldInfoMap = shuffleLocalNewSiteInfos.get(0).fieldInfoMap
          }
          if(cacheLocalNewSiteInfos.nonEmpty){
            cacheFieldInfoMap = cacheLocalNewSiteInfos.get(0).fieldInfoMap
          }
        }
        if (shufflefieldInfoMap.nonEmpty || phase.kind == "Result") {
          val optionInfoJsonList = new util.ArrayList[(String, String)]()
          phase.kind match {
            case "Shuffle" =>
              if (phase.getParents().nonEmpty) {
                val preStageId: Int = phase.id - 1
                val (optionName, typeInfo) = ("read", allStageKeyValueTypeJsonMap(preStageId).filter(_._1 == "write").head._2)
                optionInfoJsonList.add((optionName, typeInfo))
              }
              //拿到localNewSiteInfo里面的字段信息，并处理成系统定义的Json格式的字符串返回
              val stageKeyValueTypeInfoJson = KeyValueUtil.putKeyAndValueType(shufflefieldInfoMap)
              val (optionName, typeInfo): (String, String) = ("write", stageKeyValueTypeInfoJson)
              optionInfoJsonList.add((optionName, typeInfo))
              allStageKeyValueTypeJsonMap(phase.id) = optionInfoJsonList
            ...... ......
    }
    //返回记录所有stage的字段信息的map
    allStageKeyValueTypeJsonMap
  }
```
以上是Deca对截获的SparkJob的大致处理过程，调用DecaCotext.runJob->DecaContext.anaylze->DAGAnalyzer.formPhase。

**控制全局的类：**

* cn.edu.hust.grid.soot.optimize.Context

    说明：包含全局变量和soot分析时会调用到的相关方法

* org.apache.spark.DecaContext

    说明：程序分析的入口，截获job，重写spark的runJob方法

* org.apache.spark.scheduler.DAGAnalyzer

    说明：完成每个stage-DAG的迭代融合和分析优化

* org.apache.spark.scheduler.Phase

    说明：记录每个stage的id，finalRDD，此stage的父stage对应的Phase。

* cn.edu.hust.grid.deca.KeyValueUtil.java

    说明：定义了携带Stage字段信息的Json结构和相关方法

* cn.edu.hust.grid.deca.FieldTypeName

    说明：存放字段类型的类，目前只含原生类型

下面对每个formPhase方法里面的迭代融合和指针分析这两个模块涉及的类以及执行流程进行详细说明。

**************************

## <span id="1">1.Preprocssing：迭代融合</span>
### 主要涉及的类：

* cn.edu.hust.grid.soot.optimize.IteratorFusion

    说明：用于将一个stage的所有的RDD方法融合在一个loop中。具体是判断loop body的类型，用Soot生成loop body的代码，提取stage中RDD的所有UDF注入到loop body中，并保持UDF之间数据传递的一致性。

* cn.edu.hust.grid.soot.template.CacheLoopTemplate

    说明：ResultStage中包含cache时融合所需的loop body模版

* cn.edu.hust.grid.soot.template.LoopTemplate

    说明：ResultStage中不包含cache时融合所需的loop body模版

* cn.edu.hust.grid.soot.template.ShuffleCacheLoopTemplate

    说明：ShuffleStage中包含cache时融合所需的loop body模版    

* cn.edu.hust.grid.soot.template.ShuffleLoopTemplate

    说明：ShuffleStage中不包含cache时融合所需的loop body模版

###具体执行流程
之前介绍了执行流程的概要，这里介绍对每个Phase是怎么进行迭代融合的(以ShuffleStage对应的Phase为例)。下面是DAGAnalyzer.fuseIter源码:

```scala
 def fuseIter(phase: Phase, resultFuncTuple: (String, ResultType)): SootClass = {
    var fusionClass: SootClass = null
    if (allPhasesMap(phase).isInstanceOf[ResultStage]) {
        ...... ......
        ...... ......
    } else {
      //ShuffleMapStage
      phase.kind = "Shuffle"
      if (cachePhasesMap.contains(phase)) {
        //这里需要划分为两个子Phase
        val cacheWritePhase = cachePhasesMap(phase).get(0)
        val cacheReadPhase = cachePhasesMap(phase).get(1)
        val cacheWriteFuncs = loadRDDFunc(cacheWritePhase, sootContext)
        val cacheReadFuncs = loadRDDFunc(cacheReadPhase, sootContext
        if (cacheWritePhase.dataSource.equals("hadoop") || cacheReadPhase.dataSource.equals("hadoop")) {
          phase.dataSource = "hadoop"
        }
        if(phase.id==0 && phase.dataSource!="hadoop"){
          throw OptimizeException("The first stage's dataSource isn't 'hadoop'")
        }
        if (cacheReadFuncs.nonEmpty) {
          cacheReadFuncs.dequeue()
        }
        fusionClass = IteratorFusion.transformShufflePhase(sootContext, phase, cacheWriteFuncs, cacheReadFuncs)
      } else {
        //不含cache的Shuffle操作
        loadRDDFunc(phase, sootContext)
        if(phase.id==0 && phase.dataSource!="hadoop"){
          throw OptimizeException("The first stage's dataSource isn't 'hadoop'")
        }
        fusionClass = IteratorFusion.transformShufflePhase(sootContext, phase)
      }
    }
    sootContext.fusionClassList.clear()
    fusionClass
  }
```

上述源码中对含有Cache的ShuffleStage，从cachePhasesMap中拿到cacheWritePhase和cacheReadPhase， 然后调用关键方法loadRDDFunc和IteratorFusion.transformShufflePhase。loadRDDfunc主要通过反射获取RDD链的UDF，并将其放入Context类里面的fusionClassList里面为transform做准备。

我们详细介绍函数迭代融合的主体函数[transformShufflePhase](https://github.com/SCTS/Flint/blob/merge/analyzer/src/main/scala/cn/edu/hust/grid/soot/optimize/IteratorFusion.scala)，是将一个RDD链的所有UDF放入一个循环体中，构成一个新的UDF,具体处理逻辑如下：

1.调用initResultClass方法，判断stage的类型（shuffle/result）以及是否有cache操作，从而确定loop的结构，获取对应loop模版的loopFunc，使用Soot生成新的SooClass，并将其loopFunc注入后返回。

```scala
val resultClass: SootClass = initResultClass(phase, context)
```

2.使用Soot将Context类里面的fusionClassList的func注入到上一步生成的resultClass的loopFunc中。

融合的时候有无cache的差别比较大，这里分别介绍：

* Stage中无Cache

  对fusionClassList的每一个fusionClass，获取其Apply方法的方法体，源码如下：

  ```scala
          val applyMethod = getApplyMethod(fusionClass, context)
          val methodBody = Utils.cloneSootBody(applyMethod.getActiveBody)
  ```

  然后获取locals，并将其加入resultClass的loopFunc中

  ```scala
    //添加locals
          for (local <- methodBody.getLocals) {
            // 不添加thisLocal
            if (local.getType.toString.equals(fusionClass.getName)) {
              local.setType(resultClass.getType)
            }
            newLoopMethod.getActiveBody.getLocals.addLast(local)
          }
  ```

  然后添加units，判断每条语句的类型（包括声明，赋值，调用，判断，返回等）根据方法体的逻辑插入resultClass的loopFunc中。

  **注：对于filter，MapValues，flatMap等算子需根据算子的语义做特殊化处理**

* Stage中有Cache

  我们先看一下这种情况下shuffleStage对应的loop模版：

  ```scala
  package cn.edu.hust.grid.soot.template
  class ShuffleCacheLoopTemplate(rddId: Int) {
    def loopFunc[U](taskContext: DecaTaskContext, id: Int, iterator: DataSourceIterator): Unit = {
      val blockId = rddId.toString + id.toString
      val isCache = DecaBlockManager.isContainBlock(blockId)
      if (isCache) {
        val iter = DecaBlockManager.getIter(blockId)
        while (iter.hasNext) {
          val element = iter.next().asInstanceOf[Integer]
          DecaShuffleManager.writeElement(element)
        }
      } else {
        //cacheWrite
        while (iterator.hasNext) {
          val element = iterator.next().asInstanceOf[Integer]
          DecaBlockManager.writeElement(element)
        }
        //cacheRead
        val iter = DecaBlockManager.getIter(blockId)
        while (iter.hasNext) {
          val element = iter.next().asInstanceOf[Integer]
          DecaShuffleManager.writeElement(element)
        }
      }
    }
  }

  ```

  从上述源码中可以看出，如果是CacheRDD的话，新增加了一个循环直接在cache buffer中处理。如果不是cacheRDD的话，cacheWiritePhase和cacheReadPhase对应了两个不同的循环，因为cacheWiritePhase是写入cache buffer，cacheReadPhase是写入shuffe buffer。

  从DAGAnalyzer.fuseIter中我们可以看到调用transformShufflePhase如下：

  ```scala
  fusionClass = IteratorFusion.transformShufflePhase(sootContext, phase, cacheWriteFuncs, cacheReadFuncs)
  ```

  传入了cacheWriteFuncs和cacheReadFuncs，分别将其注入到resultClass里面的loopFunc中。融合逻辑是如果存在cache，则直接读，如果没有，则调用写，然后读。

3.融合完成后，调用finishResultClass，添加apply(object,object,object)方法和cinit方法，返回融合完成后的resultClass。

## <Span id="2">2.Analysis：指针分析</Span>

### 主要涉及的类

* cn.edu.hust.grid.soot.optimize.PointerAnalyzer

  说明： 利用SPARK框架对上一阶段融合生成的funcClass进行指针分析，得到new Site

* cn.edu.hust.grid.soot.template.InvokeFunc

  说明：调用funcClass的模板

* cn.edu.hust.grid.deca.iter.ShuffleData

  说明：用来记录Shuffle操作中数据类型

* cn.edu.hust.grid.soot.optimize.LocalNewSiteInfo

  说明：用于拆解类和代码转换的信息

* cn.edu.hust.grid.soot.optimize.FieldInfo

  说明：记录字段的类信息，是否为数组，以及其子field

* cn.edu.hust.grid.soot.optimize.SootSite

  说明：记录引用类型的字段的new site信息

###具体执行流程

融合结束后，执行指针分析，指针分析使用了[geomPTA](https://github.com/Sable/soot/wiki/Using-Geometric-Encoding-based-Context-Sensitive-Points-to-Analysis-%28geomPTA%29),它是基于Spark的上下文敏感的指针分析。

指针分析的入口函数PointerAnalyzer.transform，源码如下：

```scala
def transform(context: Context, fusionClass: SootClass, phase: Phase): util.List[LocalNewSiteInfo] = {
  addInit(fusionClass, context)
  val invokeClass = addStaticMain(fusionClass, context, phase)
  // 必须要写，接下来的全量加载需要这两个文件
  context.writeOutput(invokeClass)
  context.writeOutput(fusionClass)
  val loadClassStart = System.currentTimeMillis()
  val newContext = getNewContext()
  val loadClassEnd = System.currentTimeMillis()
  TimeRecorder.loadClassTime = loadClassEnd - loadClassStart
  newContext.writeOutput(newContext.sootClass(invokeClass.getName))
  newContext.writeOutput(newContext.sootClass(fusionClass.getName))
  newContext.writeOutput(newContext.sootClass("cn.edu.hust.grid.deca.iter.HadoopIterator"))
  newContext.writeOutput(newContext.sootClass("cn.edu.hust.grid.deca.iter.DecaShuffleIterator"))
  newContext.writeOutput(newContext.sootClass("cn.edu.hust.grid.deca.iter.DataSourceIterator"))
  val pointerAnalyzeStart = System.currentTimeMillis()
  newContext.scene.setEntryPoints(EntryPoints.v().application())
  val map = new java.util.HashMap[String, String]()
  //设置Spark转换分析的相关参数
  map.put("enabled", "true")
  map.put("set-impl", "hash")
  map.put("on-fly-cg", "true")
  map.put("propagator", "worklist")
  map.put("verbose", "true")
  map.put("geom-blocking", "true")
  map.put("geom-runs", "2")
  map.put("geom-encoding", "Geom")
  map.put("geom-worklist", "PQ")
  map.put("field-based", "false")
  map.put("geom-pta", "true")
  SparkTransformer.v.transform("", map)
  val pa = newContext.scene.getPointsToAnalysis
  DAGAnalyzer.sootContext = newContext
  val newSiteInfoList = handlePointer(fusionClass, pa, newContext)
  val pointerAnalyzeEnd = System.currentTimeMillis()
  TimeRecorder.pointerAnalysisTime = pointerAnalyzeEnd - pointerAnalyzeStart
  newSiteInfoList
}
```

然后跳转到handlePointer函数

```scala
private def handlePointer(fusionClass: SootClass, pa: PointsToAnalysis, context: Context): util.List[LocalNewSiteInfo] = {
  val funcClass = context.sootClass(fusionClass.getName)
  finalFuncClass = funcClass
  val applyMethod = IteratorFusion.getApplyMethod(funcClass, context)
  //获取applyMethod方法中被写的local，包括cache和shuffle
  val localList = getWriteLocals(applyMethod)
  val newSiteInfoList = new util.ArrayList[LocalNewSiteInfo]()
  for (local <- localList) {
    val localNewSiteInfo = getLocalNewSiteInfo(local, pa, funcClass, context)
    lbgfsNum = 0
    if (localNewSiteInfo != null) {
      if(localFromShuffleOrCache(local) == "shuffle"){
        localNewSiteInfo.genericType = "shuffle"
      }else if(localFromShuffleOrCache(local) == "cache"){
        localNewSiteInfo.genericType = "cache"
      }else{
        localNewSiteInfo.genericType = "undefined"
      }
      newSiteInfoList.add(localNewSiteInfo)
    }
  }
  newSiteInfoList
}
```

然后对localList中每一个local执行[getLocalNewSiteInfo](https://github.com/SCTS/Flint/blob/merge/analyzer/src/main/scala/cn/edu/hust/grid/soot/optimize/PointerAnalyzer.scala)（请结合代码食用）：

1.用reachingObject获取local的指针信息，即被创建的地方，结果存放在PointsToSet中，为了可以通过迭代器获取里面的信息，将PointsToSet强制类型转换为PointsToSetInternal。

2.PointsToSetInternal类中有一个forall函数，用户可以自定义visit函数。本系统中自定义的visit函数只处理new site唯一的情况。如下：

（1）：判断setSootFieldMap中是否含有当前的p2set（PointsToSet），若有，则跳到（5）；若无，则通过AllocNode获取SootSite包含local所在的类，所在的方法，被创建的语句，以及调用init的语句；

（2）：通过AllocNode的type获取local的类型，进而获取所在该类的SootField。

（3）：对每个SootField，获取其PointsToSet，若不为空，表明是引用类型，并生成FieldInfo，用一个 setSootFieldMap记录该字段对应的PointsToSet，并记录field的父子关系；若是空，则是原生类型，直接生成FieldInfo；（对象数组？）

（4）：对上一步生成的PointsToSet，执行forall函数，回到First

（5）：从setSootFieldMap获取当前p2Set对应的SootField，然后获取SootField的SootSite，并更新fieldInfo，跳到（2）。

3.最后返回localNewSiteInfo。



